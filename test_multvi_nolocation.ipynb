{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvi\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import h5py    \n",
    "import numpy as np   \n",
    "import scipy.sparse as sparse\n",
    "import scipy.io as sio\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chro' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/haiyi/Desktop/HierachicalCausal_Omics/test_multvi_nolocation.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haiyi/Desktop/HierachicalCausal_Omics/test_multvi_nolocation.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m modality \u001b[39m=\u001b[39m [text\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m modality]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haiyi/Desktop/HierachicalCausal_Omics/test_multvi_nolocation.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m interval_pd \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(interval)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/haiyi/Desktop/HierachicalCausal_Omics/test_multvi_nolocation.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m table\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray([ID, ID, modality, chro, start, end])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haiyi/Desktop/HierachicalCausal_Omics/test_multvi_nolocation.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m table2\u001b[39m=\u001b[39mtable\u001b[39m.\u001b[39mtranspose()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/haiyi/Desktop/HierachicalCausal_Omics/test_multvi_nolocation.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(table2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chro' is not defined"
     ]
    }
   ],
   "source": [
    "## import dataset of 10x_AD raw data\n",
    "feature = h5py.File(\"./data/Multiome_RNA_ATAC_Mouse_Brain_Alzheimers_AppNote_filtered_feature_bc_matrix.h5\",'r+')    \n",
    "feature_file = feature[\"matrix\"][\"features\"]\n",
    "ID = feature_file['id'][:]\n",
    "modality = feature_file[\"feature_type\"][:]\n",
    "interval = feature_file[\"interval\"][:]\n",
    "name = feature_file[\"name\"][:]\n",
    "interval = [text.decode(\"utf-8\")  for text in interval]\n",
    "interval = [text.replace(':', '\\t') for text in interval]\n",
    "interval = [text.replace('-', '\\t') for text in interval]\n",
    "interval = [text.split('\\t') for text in interval]\n",
    "ID = [text.decode(\"utf-8\")  for text in ID]\n",
    "modality = [text.decode(\"utf-8\")  for text in modality]\n",
    "interval_pd = pd.DataFrame(interval)\n",
    "table=np.array([ID, ID, modality, chro, start, end])\n",
    "table2=table.transpose()\n",
    "df = pd.DataFrame(table2)\n",
    "df.to_csv(\"features.tsv\", header=None, index=False, sep='\\t')\n",
    "data = feature[\"matrix\"]\n",
    "M1 = sparse.csc_matrix((data['data'][:],data['indices'][:], data['indptr'][:]), data['shape'][:])\n",
    "sio.mmwrite(\"matrix.mtx\",M1)\n",
    "barcodes = [text.decode(\"utf-8\")  for text in feature[\"matrix\"]['barcodes'][:]]\n",
    "barcodes = [text.replace('-', '_')  for text in barcodes]\n",
    "barcodes = [text + '-'+text[text.find('_')+1:]  for text in barcodes]\n",
    "barcodes = pd.DataFrame(barcodes)\n",
    "barcodes.to_csv(\"data/10X_AD/barcodes.tsv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/data/_read.py:78: FutureWarning: X.dtype being converted to np.float32 from int64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  return AnnData(data.tocsr(), var=features, obs=cell_annot)\n"
     ]
    }
   ],
   "source": [
    "adata_multi = scvi.data.read_10x_multiome(\"data/10X_AD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_mvi = scvi.data.organize_multiome_anndatas(adata_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.model.MULTIVI.setup_anndata(adata_mvi, batch_key=\"modality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = scvi.model.MULTIVI(adata_mvi, 32286, 66914)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|                                                  | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/module/_multivae.py:557: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/aten/src/ATen/native/TensorShape.cpp:2985.)\n",
      "  x = torch.where(mask_expr.T, x_expr.T, x_acc.T).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|████████████████| 10/10 [04:11<00:00, 25.13s/it, loss=7.68e+03, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "vae.train(use_gpu=True, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "from typing import Dict, Iterable, List, Optional, Sequence, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from scvi import REGISTRY_KEYS\n",
    "from scvi._compat import Literal\n",
    "from scvi._types import Number\n",
    "from scvi._utils import _doc_params\n",
    "from scvi.data import AnnDataManager\n",
    "from scvi.data.fields import (\n",
    "    CategoricalJointObsField,\n",
    "    CategoricalObsField,\n",
    "    LayerField,\n",
    "    NumericalJointObsField,\n",
    "    NumericalObsField,\n",
    ")\n",
    "from scvi.dataloaders import DataSplitter\n",
    "from scvi.model._utils import (\n",
    "    _get_batch_code_from_category,\n",
    "    scatac_raw_counts_properties,\n",
    "    scrna_raw_counts_properties,\n",
    ")\n",
    "from scvi.model.base import UnsupervisedTrainingMixin\n",
    "from scvi.module import MULTIVAE\n",
    "from scvi.train import AdversarialTrainingPlan, TrainRunner\n",
    "from scvi.train._callbacks import SaveBestState\n",
    "from scvi.utils._docstrings import doc_differential_expression, setup_anndata_dsp\n",
    "\n",
    "from scvi.model import MULTIVI \n",
    "\n",
    "from scvi.model.base import BaseModelClass, VAEMixin\n",
    "from scvi.model.base._utils import _de_core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiVI_Parallel(MULTIVI):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        adata: AnnData,\n",
    "        n_genes: int,\n",
    "        n_regions: int,\n",
    "        n_hidden: Optional[int] = None,\n",
    "        n_latent: Optional[int] = None,\n",
    "        n_layers_encoder: int = 2,\n",
    "        n_layers_decoder: int = 2,\n",
    "        dropout_rate: float = 0.1,\n",
    "        region_factors: bool = True,\n",
    "        gene_likelihood: Literal[\"zinb\", \"nb\", \"poisson\"] = \"zinb\",\n",
    "        use_batch_norm: Literal[\"encoder\", \"decoder\", \"none\", \"both\"] = \"none\",\n",
    "        use_layer_norm: Literal[\"encoder\", \"decoder\", \"none\", \"both\"] = \"both\",\n",
    "        latent_distribution: Literal[\"normal\", \"ln\"] = \"normal\",\n",
    "        deeply_inject_covariates: bool = False,\n",
    "        encode_covariates: bool = False,\n",
    "        fully_paired: bool = False,\n",
    "        **model_kwargs,\n",
    "    ):\n",
    "        super().__init__(adata,\n",
    "        n_genes,\n",
    "        n_regions,\n",
    "        n_hidden,\n",
    "        n_latent,\n",
    "        n_layers_encoder,\n",
    "        n_layers_decoder,\n",
    "        dropout_rate,\n",
    "        region_factors,\n",
    "        gene_likelihood,\n",
    "        use_batch_norm,\n",
    "        use_layer_norm,\n",
    "        latent_distribution,\n",
    "        deeply_inject_covariates,\n",
    "        encode_covariates,\n",
    "        fully_paired,\n",
    "        **model_kwargs,)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_latent_representation(\n",
    "        self,\n",
    "        adata: Optional[AnnData] = None,\n",
    "        modality: Literal[\"joint\", \"expression\", \"accessibility\"] = \"joint\",\n",
    "        indices: Optional[Sequence[int]] = None,\n",
    "        give_mean: bool = True,\n",
    "        batch_size: Optional[int] = None,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Return the latent representation for each cell.\n",
    "        Parameters\n",
    "        ----------\n",
    "        adata\n",
    "            AnnData object with equivalent structure to initial AnnData. If `None`, defaults to the\n",
    "            AnnData object used to initialize the model.\n",
    "        modality\n",
    "            Return modality specific or joint latent representation.\n",
    "        indices\n",
    "            Indices of cells in adata to use. If `None`, all cells are used.\n",
    "        give_mean\n",
    "            Give mean of distribution or sample from it.\n",
    "        batch_size\n",
    "            Minibatch size for data loading into model. Defaults to `scvi.settings.batch_size`.\n",
    "        Returns\n",
    "        -------\n",
    "        latent_representation : np.ndarray\n",
    "            Low-dimensional representation for each cell\n",
    "        \"\"\"\n",
    "        if not self.is_trained_:\n",
    "            raise RuntimeError(\"Please train the model first.\")\n",
    "\n",
    "        keys = {\"z\": \"z\", \"qz_m\": \"qz_m\", \"qz_v\": \"qz_v\", \"z_expr\": \"z_expr\", \n",
    "        \"qzm_expr\": \"qzm_expr\", \"qzv_expr\": \"qzv_expr\", \"z_acc\": \"z_acc\", \"qzm_acc\": \"qzm_acc\", \"qzv_acc\": \"qzv_acc\"}\n",
    "        \n",
    "\n",
    "        adata = self._validate_anndata(adata)\n",
    "        scdl = self._make_data_loader(\n",
    "            adata=adata, indices=indices, batch_size=batch_size\n",
    "        )\n",
    "        latent = []\n",
    "        latent_expr = []\n",
    "        latent_atac = []\n",
    "        for tensors in scdl:\n",
    "            inference_inputs = self.module._get_inference_input(tensors)\n",
    "            outputs = self.module.inference(**inference_inputs)\n",
    "            qz_m = outputs[keys[\"qz_m\"]]\n",
    "            qz_v = outputs[keys[\"qz_v\"]]\n",
    "            z = outputs[keys[\"z\"]]\n",
    "            \n",
    "            qzm_expr = outputs[keys[\"qzm_expr\"]]\n",
    "            qzv_expr = outputs[keys[\"qzv_expr\"]]\n",
    "            z_expr = outputs[keys[\"z_expr\"]]\n",
    "\n",
    "            qzm_acc = outputs[keys[\"qzm_acc\"]]\n",
    "            qzm_acc = outputs[keys[\"qzv_acc\"]]\n",
    "            z_acc = outputs[keys[\"z_acc\"]]\n",
    "\n",
    "\n",
    "            if give_mean:\n",
    "                # does each model need to have this latent distribution param?\n",
    "                if self.module.latent_distribution == \"ln\":\n",
    "                    samples = Normal(qz_m, qz_v.sqrt()).sample([1])\n",
    "                    z = torch.nn.functional.softmax(samples, dim=-1)\n",
    "                    z = z.mean(dim=0)\n",
    "\n",
    "                    samples_expr = Normal(qzm_expr, qzv_expr.sqrt()).sample([1])\n",
    "                    z_expr = torch.nn.functional.softmax(samples_expr, dim=-1)\n",
    "                    z_expr = z_expr.mean(dim=0)\n",
    "\n",
    "                    samples_atac = Normal(qzm_acc, qzm_acc.sqrt()).sample([1])\n",
    "                    z_acc = torch.nn.functional.softmax(samples_atac, dim=-1)\n",
    "                    z_acc = z_acc.mean(dim=0)\n",
    "\n",
    "                else:\n",
    "                    z = qz_m\n",
    "                    z_acc = qzm_acc\n",
    "                    z_expr = qzm_expr\n",
    "\n",
    "            \n",
    "            latent += [z.cpu()]\n",
    "            latent_atac+= [z_acc.cpu()]\n",
    "            latent_expr += [z_expr.cpu()]\n",
    "\n",
    "        return torch.cat(latent).numpy() , torch.cat(latent_atac).numpy(), torch.cat(latent_expr).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiVI_Parallel.setup_anndata(adata_mvi, batch_key=\"modality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = MultiVI_Parallel(adata_mvi, 32286, 66914)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/module/_multivae.py:557: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484775609/work/aten/src/ATen/native/TensorShape.cpp:2985.)\n",
      "  x = torch.where(mask_expr.T, x_expr.T, x_acc.T).T\n",
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "vae.train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "halo",
   "language": "python",
   "name": "halo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

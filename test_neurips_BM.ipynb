{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Iterable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Normal, Poisson\n",
    "from torch.distributions import kl_divergence as kld\n",
    "from torch import tensor\n",
    "from complementary_models import HALOVIR as HALOVI\n",
    "from complementary_models import HALOVAER as HALOVAE\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import pandas as pd\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 10862 × 129921\n",
       "    obs: 'GEX_pct_counts_mt', 'GEX_n_counts', 'GEX_n_genes', 'GEX_size_factors', 'GEX_phase', 'ATAC_nCount_peaks', 'ATAC_atac_fragments', 'ATAC_reads_in_peaks_frac', 'ATAC_blacklist_fraction', 'ATAC_nucleosome_signal', 'cell_type', 'batch', 'ATAC_pseudotime_order', 'GEX_pseudotime_order', 'Samplename', 'Site', 'DonorNumber', 'Modality', 'VendorLot', 'DonorID', 'DonorAge', 'DonorBMI', 'DonorBloodType', 'DonorRace', 'Ethnicity', 'DonorGender', 'QCMeds', 'DonorSmoker', 'modality'\n",
       "    var: 'feature_types', 'gene_id'\n",
       "    uns: 'ATAC_gene_activity_var_names', 'dataset_id', 'genome', 'organism'\n",
       "    obsm: 'ATAC_gene_activity', 'ATAC_lsi_full', 'ATAC_lsi_red', 'ATAC_umap', 'GEX_X_pca', 'GEX_X_umap'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test whole data with RNA only \n",
    "# adata_multi = sc.read_h5ad(\"halo/E18_mouse_Brain/multiomic.h5ad\")\n",
    "# adata_multi.obs[\"batch_id\"] = 1\n",
    "# adata_multi.var[\"modality\"] =adata_multi.var[\"feature_types\"]\n",
    "# adata_mvi = scvi.data.organize_multiome_anndatas(adata_multi)\n",
    "\n",
    "\n",
    "# df_meta= pd.read_csv(\"halo/E18_mouse_Brain/RNA/metadata.tsv\",sep = \"\\t\",index_col=0)\n",
    "# bins = df_meta.binned.unique()\n",
    "# times = {}\n",
    "# index = 0\n",
    "# for bin in sorted(bins):\n",
    "#     times[bin] = index\n",
    "#     index += 1\n",
    "\n",
    "# def add_time(row, times):\n",
    "#     timestamp = times[row.binned]\n",
    "#     return timestamp\n",
    "\n",
    "# df_meta['time_key'] = df_meta.apply(lambda row: add_time(row, times), axis=1)\n",
    "\n",
    "# newindex = []\n",
    "\n",
    "# for idx, row in df_meta.iterrows():\n",
    "#     newindex.append(idx+\"_paired\")\n",
    "\n",
    "# df_meta['Id'] = newindex    \n",
    "\n",
    "# df_meta_sub = df_meta[[\"Id\", 'latent_time']]\n",
    "\n",
    "# df_meta_sub.set_index(\"Id\", inplace=True)\n",
    "# adata_mvi.obs = adata_mvi.obs.join(df_meta_sub, how=\"inner\")\n",
    "# sc.pp.filter_genes(adata_mvi, min_cells=int(adata_mvi.shape[0] * 0.01))\n",
    "\n",
    "\n",
    "\n",
    "adata_multi = sc.read_h5ad(\"openproblem/neurips_traj.h5ad\")\n",
    "adata_multi.X = adata_multi.layers['counts']\n",
    "newadata = adata_multi[adata_multi.obs['GEX_pseudotime_order'].notna()].copy()\n",
    "adata_mvi = scvi.data.organize_multiome_anndatas(newadata)\n",
    "\n",
    "adata_mvi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HALOVI.setup_anndata(adata_mvi, batch_key=\"batch\", time_key='GEX_pseudotime_order')\n",
    "model = HALOVI(\n",
    "    adata_mvi,\n",
    "    n_genes=(adata_mvi.var['feature_types']=='GEX').sum(),\n",
    "    n_regions=(adata_mvi.var['feature_types']=='ATAC').sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=10 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 10/10 [01:17<00:00,  7.72s/it, loss=4.64e+04, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=True, acc_train=True)\n",
    "model.module.set_finetune_params(0)\n",
    "model.train(max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=10 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 10/10 [01:12<00:00,  7.28s/it, loss=4.11e+03, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=True, acc_train=False)\n",
    "model.module.set_finetune_params(0)\n",
    "model.train(max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=10 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 10/10 [01:11<00:00,  7.11s/it, loss=1.12e+04, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=False, acc_train=True)\n",
    "model.module.set_finetune_params(0)\n",
    "model.train(max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=100 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100:  13%|█▎        | 13/100 [02:16<15:06, 10.42s/it, loss=1.45e+05, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=True, acc_train=True)\n",
    "model.module.set_finetune_params(2)\n",
    "model.train(max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=100 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 100/100 [12:57<00:00,  7.78s/it, loss=4.54e+04, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=True, acc_train=True)\n",
    "model.module.set_finetune_params(0)\n",
    "model.train(max_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cat(latent_expr).numpy(), torch.cat(latent_atac).numpy(), \\\n",
    "            torch.cat(latent_expr_dep).numpy(), torch.cat(latent_atac_dep).numpy(), \\\n",
    "                torch.cat(latent_expr_indep).numpy(), torch.cat(latent_atac_indep).numpy(), torch.cat(times).numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_expr, latent_acc,latent_expr_dep, latent_atac_dep, latent_expr_indep, latent_atac_indep, times  = model.get_latent_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10862, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_atac_indep.shape\n",
    "times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 10862 × 129921\n",
       "    obs: 'GEX_pct_counts_mt', 'GEX_n_counts', 'GEX_n_genes', 'GEX_size_factors', 'GEX_phase', 'ATAC_nCount_peaks', 'ATAC_atac_fragments', 'ATAC_reads_in_peaks_frac', 'ATAC_blacklist_fraction', 'ATAC_nucleosome_signal', 'cell_type', 'batch', 'ATAC_pseudotime_order', 'GEX_pseudotime_order', 'Samplename', 'Site', 'DonorNumber', 'Modality', 'VendorLot', 'DonorID', 'DonorAge', 'DonorBMI', 'DonorBloodType', 'DonorRace', 'Ethnicity', 'DonorGender', 'QCMeds', 'DonorSmoker', 'modality', '_scvi_batch', '_scvi_labels', 'leiden_latent', 'leiden_latent_dep', 'leiden_latent_indep'\n",
       "    var: 'feature_types', 'gene_id'\n",
       "    uns: 'ATAC_gene_activity_var_names', 'dataset_id', 'genome', 'organism', '_scvi_uuid', '_scvi_manager_uuid', 'neighbors', 'leiden'\n",
       "    obsm: 'ATAC_gene_activity', 'ATAC_lsi_full', 'ATAC_lsi_red', 'ATAC_umap', 'GEX_X_pca', 'GEX_X_umap', 'latent_rep', 'latent_rep_dep', 'latent_rep_indep'\n",
       "    layers: 'counts'\n",
       "    obsp: 'distances', 'connectivities'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_mvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100:  13%|█▎        | 13/100 [15:50<1:46:03, 73.14s/it, loss=1.45e+05, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "## benchmark clustering \n",
    "from sklearn.metrics.cluster import adjusted_rand_score as ARI\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "\n",
    "\n",
    "latent_rep = np.concatenate((latent_expr, latent_acc), axis=1)\n",
    "adata_mvi.obsm[\"latent_rep\"] = latent_rep\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "\n",
    "latent_rep_dep = np.concatenate((latent_expr_dep, latent_atac_dep), axis=1)\n",
    "latent_rep_dep.shape\n",
    "adata_mvi.obsm[\"latent_rep_dep\"] = latent_rep_dep\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep_dep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent_dep\", resolution=0.4)\n",
    "\n",
    "latent_rep_indep = np.concatenate((latent_expr_indep, latent_atac_indep), axis=1)\n",
    "adata_mvi.obsm[\"latent_rep_indep\"] = latent_rep_indep\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep_indep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent_indep\", resolution=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ari_whole 0.4430810226476561, nmi_whole: 0.5312440155535496\n",
      "ari_dep 0.3896577201655209, nmi_dep: 0.48522298385494855\n",
      "ari_indep 0.44435354624353146, nmi_indep: 0.5357642472369234\n"
     ]
    }
   ],
   "source": [
    "ari_whole = ARI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent'])\n",
    "\n",
    "\n",
    "nmi_dep = NMI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent_dep'])\n",
    "ari_dep = ARI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent_dep'])\n",
    "\n",
    "\n",
    "nmi_indep = NMI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent_indep'])\n",
    "ari_indep = ARI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent_indep'])\n",
    "\n",
    "print(\"ari_whole {}, nmi_whole: {}\".format(ari_whole, nmi_whole))\n",
    "print(\"ari_dep {}, nmi_dep: {}\".format(ari_dep, nmi_dep))\n",
    "print(\"ari_indep {}, nmi_indep: {}\".format(ari_indep, nmi_indep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score3 0.05627993930527525 and score4 0.0642378831053579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.0080, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from complementary_models import torch_infer_nonsta_dir\n",
    "\n",
    "\n",
    "latent_atac_indep = torch.tensor(latent_atac_indep[:5000, :]).to('cuda')\n",
    "latent_expr_indep = torch.tensor(latent_expr_indep[:5000, :]).to('cuda')\n",
    "times = torch.tensor(times[:5000, :]).to('cuda')\n",
    "\n",
    "score3, _, _ = torch_infer_nonsta_dir(latent_atac_indep, latent_expr_indep, times)\n",
    "score4, _, _ = torch_infer_nonsta_dir(latent_expr_indep, latent_atac_indep, times)\n",
    "print(\"score3 {} and score4 {}\".format(score3, score4))\n",
    "score3 - score4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1 0.05464940435763029 and score2 0.05465027092730652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-8.6657e-07, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_atac_dep = torch.tensor(latent_atac_dep[:5000, :]).to('cuda')\n",
    "latent_expr_dep = torch.tensor(latent_expr_dep[:5000, :]).to('cuda')\n",
    "# times = torch.tensor(times).to('cuda')\n",
    "\n",
    "score1, _, _ = torch_infer_nonsta_dir(latent_atac_dep, latent_expr_dep, times)\n",
    "score2, _, _ = torch_infer_nonsta_dir(latent_expr_dep, latent_atac_dep, times)\n",
    "print(\"score1 {} and score2 {}\".format(score1, score2))\n",
    "score1 - score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MultiVI and GLUE test\n",
    "\n",
    "HALOVI.setup_anndata(adata_mvi, batch_key=\"batch\", time_key='GEX_pseudotime_order')\n",
    "model2 = HALOVI(\n",
    "    adata_mvi,\n",
    "    n_genes=(adata_mvi.var['feature_types']=='GEX').sum(),\n",
    "    n_regions=(adata_mvi.var['feature_types']=='ATAC').sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=20 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 20/20 [02:39<00:00,  7.96s/it, loss=4.68e+04, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model2.module.set_train_params(expr_train=True, acc_train=True)\n",
    "model.module.set_finetune_params(0)\n",
    "model2.train(max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_expr, latent_acc,latent_expr_dep, latent_atac_dep, latent_expr_indep, latent_atac_indep, times  = model2.get_latent_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_multi_VI = 1/2 * (latent_expr[:5000, :]+ latent_acc[:5000, :])\n",
    "z_multi_VI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0.33799443287137076, NMI 0.5034644361297838\n"
     ]
    }
   ],
   "source": [
    "## evaluate clustering\n",
    "\n",
    "from sklearn.metrics.cluster import adjusted_rand_score as ARI\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "\n",
    "\n",
    "latent_rep = np.concatenate((latent_expr, latent_acc), axis=1)\n",
    "adata_mvi.obsm[\"latent_rep\"] = latent_rep\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent'])\n",
    "\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0.3243323806046435, NMI 0.496832264818793\n"
     ]
    }
   ],
   "source": [
    "z_multi_VI = 1/2 * (latent_expr+ latent_acc)\n",
    "adata_mvi.obsm[\"latent_rep\"] = z_multi_VI\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent'])\n",
    "\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0.1379728188454027, NMI 0.32919537383442593\n",
      "ARI 0.14783618451466504, NMI 0.2825659254404057\n"
     ]
    }
   ],
   "source": [
    "gene_expr = adata_mvi.X[:, :13431]\n",
    "gene_peak = adata_mvi.X[:, 13431:]\n",
    "\n",
    "Gene_PCA = sc.pp.pca(gene_expr, n_comps=10)\n",
    "\n",
    "adata_mvi.obsm[\"latent_rep\"] = Gene_PCA\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent'])\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))\n",
    "\n",
    "Peak_SVD = sc.pp.pca(gene_peak, n_comps=10, svd_solver='arpack')\n",
    "adata_mvi.obsm[\"latent_rep\"] = Peak_SVD\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['cell_type'], adata_mvi.obs['leiden_latent'])\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20139/3730558050.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  times = torch.tensor(times[:5000, :]).to('cuda')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1 0.05511208374970013 and score2 0.05498806455610048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from complementary_models import torch_infer_nonsta_dir\n",
    "\n",
    "length=z_multi_VI.shape[1]\n",
    "scores = []\n",
    "z_multi_acc = z_multi_VI[: ,:5]\n",
    "z_multi_expr = z_multi_VI[: ,5:]\n",
    "\n",
    "z_multi_acc = torch.tensor(z_multi_acc).to('cuda')\n",
    "z_multi_expr = torch.tensor(z_multi_expr).to('cuda')\n",
    "times = torch.tensor(times[:5000, :]).to('cuda')\n",
    "score1, _, _ = torch_infer_nonsta_dir(z_multi_acc, z_multi_expr, times)\n",
    "score2, _, _ = torch_infer_nonsta_dir(z_multi_expr, z_multi_acc, times)\n",
    "\n",
    "# for i in range(0, length, 2):\n",
    "#     z1 =  torch.tensor(z_multi_VI[:, i]).to('cuda')\n",
    "#     z2 = torch.tensor(z_multi_VI[:, i+1]).to('cuda')\n",
    "#     print(z1.shape, z2.shape)\n",
    "#     score, _, _ = torch_infer_nonsta_dir(z1, z2, times)\n",
    "#     scores.append(score)\n",
    "\n",
    "print(\"score1 {} and score2 {}\".format(score1, score2))\n",
    "score1 - score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1 0.05500114815794869 and score2 0.05500114815794869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_acc =  torch.tensor(latent_acc[:5000, :]).to('cuda')\n",
    "glue_exp = torch.tensor(latent_expr[:5000, :]).to('cuda')\n",
    "# times = torch.tensor(times).to('cuda')\n",
    "\n",
    "score1, _, _ = torch_infer_nonsta_dir(glue_acc, glue_exp, times)\n",
    "score2, _, _ = torch_infer_nonsta_dir(glue_acc, glue_exp, times)\n",
    "\n",
    "print(\"score1 {} and score2 {}\".format(score1, score2))\n",
    "score1 - score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13431\n",
      "116490\n"
     ]
    }
   ],
   "source": [
    "print((adata_mvi.var[\"feature_types\"]==\"GEX\").sum())\n",
    "print((adata_mvi.var[\"feature_types\"]!=\"GEX\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10862, 13431) (10862, 116490)\n"
     ]
    }
   ],
   "source": [
    "gene_expr = adata_mvi.X[:, :13431]\n",
    "gene_peak = adata_mvi.X[:, 13431:]\n",
    "print(gene_expr.shape, gene_peak.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene_PCA = sc.pp.pca(gene_expr, n_comps=10)\n",
    "Peak_SVD = sc.pp.pca(gene_expr, n_comps=10, svd_solver='arpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1 0.0548628958826182 and score2 0.05487209351550488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-9.1976e-06, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Peak_SVD =  torch.tensor(Peak_SVD[:5000, :]).to('cuda')\n",
    "Gene_PCA = torch.tensor(Gene_PCA[:5000, :]).to('cuda')\n",
    "# times = torch.tensor(times).to('cuda')\n",
    "\n",
    "score1, _, _ = torch_infer_nonsta_dir(Peak_SVD, Gene_PCA, times)\n",
    "score2, _, _ = torch_infer_nonsta_dir(Gene_PCA, Peak_SVD, times)\n",
    "\n",
    "print(\"score1 {} and score2 {}\".format(score1, score2))\n",
    "score1 - score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('halo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8353fad07efb87fed686271f8c766cb24580e47ae7007e28a3b0368661d8351"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

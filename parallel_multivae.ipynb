{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, Iterable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Normal, Poisson\n",
    "from torch.distributions import kl_divergence as kld\n",
    "\n",
    "from scvi import REGISTRY_KEYS\n",
    "from scvi._compat import Literal\n",
    "from scvi.distributions import NegativeBinomial, ZeroInflatedNegativeBinomial\n",
    "from scvi.module._peakvae import Decoder as DecoderPeakVI\n",
    "from scvi.module.base import BaseModuleClass, LossRecorder, auto_move_data\n",
    "from scvi.nn import DecoderSCVI, Encoder, FCLayers\n",
    "from scvi.module import MULTIVAE\n",
    "\n",
    "from anndata import AnnData\n",
    "from typing import Dict, Iterable, List, Optional, Sequence, Union\n",
    "from scvi.model import MULTIVI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MULTIVAE_Parallel(MULTIVAE):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_regions: int = 0,\n",
    "        n_input_genes: int = 0,\n",
    "        n_batch: int = 0,\n",
    "        gene_likelihood: Literal[\"zinb\", \"nb\", \"poisson\"] = \"zinb\",\n",
    "        n_hidden: Optional[int] = None,\n",
    "        n_latent: Optional[int] = None,\n",
    "        n_layers_encoder: int = 2,\n",
    "        n_layers_decoder: int = 2,\n",
    "        n_continuous_cov: int = 0,\n",
    "        n_cats_per_cov: Optional[Iterable[int]] = None,\n",
    "        dropout_rate: float = 0.1,\n",
    "        region_factors: bool = True,\n",
    "        use_batch_norm: Literal[\"encoder\", \"decoder\", \"none\", \"both\"] = \"none\",\n",
    "        use_layer_norm: Literal[\"encoder\", \"decoder\", \"none\", \"both\"] = \"both\",\n",
    "        latent_distribution: str = \"normal\",\n",
    "        deeply_inject_covariates: bool = False,\n",
    "        encode_covariates: bool = False,\n",
    "        use_size_factor_key: bool = False,\n",
    "        **model_kwargs,\n",
    "\n",
    "    ):\n",
    "    \n",
    "        super().__init__(\n",
    "            n_input_regions,\n",
    "            n_input_genes,\n",
    "            n_batch,\n",
    "            gene_likelihood,\n",
    "            n_hidden,\n",
    "            n_latent,\n",
    "            n_layers_encoder,\n",
    "            n_layers_decoder,\n",
    "            n_continuous_cov,\n",
    "            n_cats_per_cov,\n",
    "            dropout_rate,\n",
    "            region_factors,\n",
    "            use_batch_norm,\n",
    "            use_layer_norm,\n",
    "            latent_distribution,\n",
    "            deeply_inject_covariates,\n",
    "            encode_covariates,\n",
    "            use_size_factor_key,\n",
    "            **model_kwargs,\n",
    ")\n",
    "        self.module =  MULTIVAE_Parallel(\n",
    "            n_input_genes=n_input_genes,\n",
    "            n_input_regions=n_input_regions,\n",
    "            n_batch=self.summary_stats.n_batch,\n",
    "            n_hidden=n_hidden,\n",
    "            n_latent=n_latent,\n",
    "            n_layers_encoder=n_layers_encoder,\n",
    "            n_layers_decoder=n_layers_decoder,\n",
    "            n_continuous_cov=self.summary_stats.get(\"n_extra_continuous_covs\", 0),\n",
    "            n_cats_per_cov=n_cats_per_cov,\n",
    "            dropout_rate=dropout_rate,\n",
    "            region_factors=region_factors,\n",
    "            gene_likelihood=gene_likelihood,\n",
    "            use_batch_norm=use_batch_norm,\n",
    "            use_layer_norm=use_layer_norm,\n",
    "            use_size_factor_key=use_size_factor_key,\n",
    "            latent_distribution=latent_distribution,\n",
    "            deeply_inject_covariates=deeply_inject_covariates,\n",
    "            encode_covariates=encode_covariates,\n",
    "            **model_kwargs,\n",
    "        )    \n",
    "\n",
    "    @auto_move_data\n",
    "    def inference(\n",
    "        self,\n",
    "        x,\n",
    "        batch_index,\n",
    "        cont_covs,\n",
    "        cat_covs,\n",
    "        n_samples=1,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        # Get Data and Additional Covs\n",
    "        x_rna = x[:, : self.n_input_genes]\n",
    "        x_chr = x[:, self.n_input_genes :]\n",
    "\n",
    "        mask_expr = x_rna.sum(dim=1) > 0\n",
    "        mask_acc = x_chr.sum(dim=1) > 0\n",
    "\n",
    "        if cont_covs is not None and self.encode_covariates:\n",
    "            encoder_input_expression = torch.cat((x_rna, cont_covs), dim=-1)\n",
    "            encoder_input_accessibility = torch.cat((x_chr, cont_covs), dim=-1)\n",
    "        else:\n",
    "            encoder_input_expression = x_rna\n",
    "            encoder_input_accessibility = x_chr\n",
    "\n",
    "        if cat_covs is not None and self.encode_covariates:\n",
    "            categorical_input = torch.split(cat_covs, 1, dim=1)\n",
    "        else:\n",
    "            categorical_input = tuple()\n",
    "\n",
    "        # Z Encoders\n",
    "        qz_acc, z_acc = self.z_encoder_accessibility(\n",
    "            encoder_input_accessibility, batch_index, *categorical_input\n",
    "        )\n",
    "        qz_expr, z_expr = self.z_encoder_expression(\n",
    "            encoder_input_expression, batch_index, *categorical_input\n",
    "        )\n",
    "        qzm_acc = qz_acc.loc\n",
    "        qzm_expr = qz_expr.loc\n",
    "        qzv_acc = qz_acc.scale**2\n",
    "        qzv_expr = qz_expr.scale**2\n",
    "        # L encoders\n",
    "        libsize_expr = self.l_encoder_expression(\n",
    "            encoder_input_expression, batch_index, *categorical_input\n",
    "        )\n",
    "        libsize_acc = self.l_encoder_accessibility(\n",
    "            encoder_input_accessibility, batch_index, *categorical_input\n",
    "        )\n",
    "\n",
    "        # ReFormat Outputs\n",
    "        if n_samples > 1:\n",
    "            untran_za = qz_acc.sample((n_samples,))\n",
    "            z_acc = self.z_encoder_accessibility.z_transformation(untran_za)\n",
    "            untran_zr = qz_expr.sample((n_samples,))\n",
    "            z_expr = self.z_encoder_expression.z_transformation(untran_zr)\n",
    "\n",
    "            libsize_expr = libsize_expr.unsqueeze(0).expand(\n",
    "                (n_samples, libsize_expr.size(0), libsize_expr.size(1))\n",
    "            )\n",
    "            libsize_acc = libsize_acc.unsqueeze(0).expand(\n",
    "                (n_samples, libsize_acc.size(0), libsize_acc.size(1))\n",
    "            )\n",
    "\n",
    "        ## Sample from the average distribution\n",
    "        # qzp_m = (qzm_acc + qzm_expr) / 2\n",
    "        # qzp_v = (qzv_acc + qzv_expr) / (2**0.5)\n",
    "        # zp = Normal(qzp_m, qzp_v.sqrt()).rsample()\n",
    "\n",
    "        ## choose the correct latent representation based on the modality\n",
    "        # qz_m = self._mix_modalities(qzp_m, qzm_expr, qzm_acc, mask_expr, mask_acc)\n",
    "        # qz_v = self._mix_modalities(qzp_v, qzv_expr, qzv_acc, mask_expr, mask_acc)\n",
    "        # z = self._mix_modalities(zp, z_expr, z_acc, mask_expr, mask_acc)\n",
    "\n",
    "        outputs = dict(\n",
    "            # z=z,\n",
    "            # qz_m=qz_m,\n",
    "            # qz_v=qz_v,\n",
    "            z_expr=z_expr,\n",
    "            qzm_expr=qzm_expr,\n",
    "            qzv_expr=qzv_expr,\n",
    "            z_acc=z_acc,\n",
    "            qzm_acc=qzm_acc,\n",
    "            qzv_acc=qzv_acc,\n",
    "            libsize_expr=libsize_expr,\n",
    "            libsize_acc=libsize_acc,\n",
    "        )\n",
    "        return outputs   \n",
    "\n",
    "\n",
    "    ### change this function \n",
    "    def _get_generative_input(self, tensors, inference_outputs, transform_batch=None):\n",
    "  \n",
    "        z_expr = inference_outputs[\"z_expr\"]\n",
    "        qzm_expr = inference_outputs[\"qzm_expr\"]\n",
    "        libsize_expr = inference_outputs[\"libsize_expr\"]\n",
    "\n",
    "\n",
    "        z_acc = inference_outputs[\"z_acc\"]\n",
    "        qzm_acc = inference_outputs[\"qzm_acc\"]\n",
    "        libsize_acc = inference_outputs[\"libsize_acc\"]\n",
    "\n",
    "        size_factor_key = REGISTRY_KEYS.SIZE_FACTOR_KEY\n",
    "        size_factor = (\n",
    "            torch.log(tensors[size_factor_key])\n",
    "            if size_factor_key in tensors.keys()\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        batch_index = tensors[REGISTRY_KEYS.BATCH_KEY]\n",
    "        cont_key = REGISTRY_KEYS.CONT_COVS_KEY\n",
    "        cont_covs = tensors[cont_key] if cont_key in tensors.keys() else None\n",
    "\n",
    "        cat_key = REGISTRY_KEYS.CAT_COVS_KEY\n",
    "        cat_covs = tensors[cat_key] if cat_key in tensors.keys() else None\n",
    "\n",
    "        if transform_batch is not None:\n",
    "            batch_index = torch.ones_like(batch_index) * transform_batch\n",
    "\n",
    "        input_dict = dict(\n",
    "            z_expr=z_expr,\n",
    "            qzm_expr=qzm_expr,\n",
    "            \n",
    "            z_acc=z_acc,\n",
    "            qzm_acc=qzm_acc,\n",
    "\n",
    "            batch_index=batch_index,\n",
    "            cont_covs=cont_covs,\n",
    "            cat_covs=cat_covs,\n",
    "            libsize_expr=libsize_expr,\n",
    "            libsize_acc = libsize_acc,\n",
    "            size_factor=size_factor,\n",
    "\n",
    "        )\n",
    "        return input_dict\n",
    "\n",
    "    @auto_move_data\n",
    "    def generative(\n",
    "        self,\n",
    "        z_expr,\n",
    "        qzm_expr,\n",
    "        z_acc,\n",
    "        qzm_acc,\n",
    "\n",
    "        batch_index,\n",
    "        cont_covs=None,\n",
    "        cat_covs=None,\n",
    "        libsize_expr=None,\n",
    "        libsize_acc= None,\n",
    "        size_factor=None,\n",
    "        use_z_mean=False,\n",
    "    ):\n",
    "        \"\"\"Runs the generative model.\"\"\"\n",
    "        if cat_covs is not None:\n",
    "            categorical_input = torch.split(cat_covs, 1, dim=1)\n",
    "        else:\n",
    "            categorical_input = tuple()\n",
    "\n",
    "        latent_expr = z_expr if not use_z_mean else qzm_expr\n",
    "        latent_acc = z_acc if not use_z_mean else qzm_acc\n",
    "        \n",
    "        if cont_covs is None:\n",
    "            decoder_input_expr = latent_expr\n",
    "            decoder_input_acc = latent_acc\n",
    "\n",
    "        elif latent_expr.dim() != cont_covs.dim():\n",
    "            \n",
    "            decoder_input_expr = torch.cat(\n",
    "                [latent_expr, cont_covs.unsqueeze(0).expand(latent_expr.size(0), -1, -1)], dim=-1\n",
    "            )\n",
    "            decoder_input_acc = torch.cat(\n",
    "                [latent_acc, cont_covs.unsqueeze(0).expand(latent_acc.size(0), -1, -1)], dim=-1\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            decoder_input_expr = torch.cat([decoder_input_expr, cont_covs], dim=-1)\n",
    "            decoder_input_acc = torch.cat([decoder_input_acc, cont_covs], dim=-1)\n",
    "\n",
    "        # Accessibility Decoder\n",
    "        p = self.z_decoder_accessibility(decoder_input_acc, batch_index, *categorical_input)\n",
    "\n",
    "        # Expression Decoder\n",
    "        if not self.use_size_factor_key:\n",
    "            size_factor = libsize_expr\n",
    "        px_scale, _, px_rate, px_dropout = self.z_decoder_expression(\n",
    "            \"gene\", decoder_input_expr, size_factor, batch_index, *categorical_input\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            p=p,\n",
    "            px_scale=px_scale,\n",
    "            px_r=torch.exp(self.px_r),\n",
    "            px_rate=px_rate,\n",
    "            px_dropout=px_dropout,\n",
    "        )         \n",
    "\n",
    "    def loss(\n",
    "        self, tensors, inference_outputs, generative_outputs, kl_weight: float = 1.0\n",
    "    ):\n",
    "        # Get the data\n",
    "        x = tensors[REGISTRY_KEYS.X_KEY]\n",
    "\n",
    "        x_rna = x[:, : self.n_input_genes]\n",
    "        x_chr = x[:, self.n_input_genes :]\n",
    "\n",
    "        mask_expr = x_rna.sum(dim=1) > 0\n",
    "        mask_acc = x_chr.sum(dim=1) > 0\n",
    "\n",
    "        # Compute Accessibility loss\n",
    "        x_accessibility = x[:, self.n_input_genes :]\n",
    "        p = generative_outputs[\"p\"]\n",
    "        libsize_acc = inference_outputs[\"libsize_acc\"]\n",
    "        rl_accessibility = self.get_reconstruction_loss_accessibility(\n",
    "            x_accessibility, p, libsize_acc\n",
    "        )\n",
    "\n",
    "        # Compute Expression loss\n",
    "        px_rate = generative_outputs[\"px_rate\"]\n",
    "        px_r = generative_outputs[\"px_r\"]\n",
    "        px_dropout = generative_outputs[\"px_dropout\"]\n",
    "        x_expression = x[:, : self.n_input_genes]\n",
    "        rl_expression = self.get_reconstruction_loss_expression(\n",
    "            x_expression, px_rate, px_r, px_dropout\n",
    "        )\n",
    "\n",
    "        # mix losses to get the correct loss for each cell\n",
    "        recon_loss = self._mix_modalities(\n",
    "            rl_accessibility + rl_expression,  # paired\n",
    "            rl_expression,  # expression\n",
    "            rl_accessibility,  # accessibility\n",
    "            mask_expr,\n",
    "            mask_acc,\n",
    "        )\n",
    "\n",
    "        # Compute KLD between Z and N(0,I)\n",
    "        # qz_m = inference_outputs[\"qz_m\"]\n",
    "        # qz_v = inference_outputs[\"qz_v\"]\n",
    "        # kl_div_z = kld(\n",
    "        #     Normal(qz_m, torch.sqrt(qz_v)),\n",
    "        #     Normal(0, 1),\n",
    "        # ).sum(dim=1)\n",
    "\n",
    "        # Compute KLD between distributions for paired data\n",
    "        qzm_expr = inference_outputs[\"qzm_expr\"]\n",
    "        qzv_expr = inference_outputs[\"qzv_expr\"]\n",
    "        qzm_acc = inference_outputs[\"qzm_acc\"]\n",
    "        qzv_acc = inference_outputs[\"qzv_acc\"]\n",
    "\n",
    "        kl_div_z = kld(\n",
    "            Normal(qzm_expr, torch.sqrt(qzv_expr)), Normal(0, 1)\n",
    "        ) + kld(\n",
    "            Normal(qzm_acc, torch.sqrt(qzv_acc)), Normal(0, 1)\n",
    "        )\n",
    "        # kld_paired = torch.where(\n",
    "        #     torch.logical_and(mask_acc, mask_expr),\n",
    "        #     kld_paired.T,\n",
    "        #     torch.zeros_like(kld_paired).T,\n",
    "        # ).sum(dim=0)\n",
    "\n",
    "        # KL WARMUP\n",
    "        kl_local_for_warmup = kl_div_z\n",
    "        weighted_kl_local = kl_weight * kl_local_for_warmup\n",
    "\n",
    "        # PENALTY\n",
    "        # distance_penalty = kl_weight * torch.pow(z_acc - z_expr, 2).sum(dim=1)\n",
    "\n",
    "        # TOTAL LOSS\n",
    "        loss = torch.mean(recon_loss + weighted_kl_local)\n",
    "\n",
    "        kl_local = dict(kl_divergence_z=kl_div_z)\n",
    "        kl_global = torch.tensor(0.0)\n",
    "        return LossRecorder(loss, recon_loss, kl_local, kl_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiVI_Parallel(MULTIVI):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        adata: AnnData,\n",
    "        n_genes: int,\n",
    "        n_regions: int,\n",
    "        n_hidden: Optional[int] = None,\n",
    "        n_latent: Optional[int] = None,\n",
    "        n_layers_encoder: int = 2,\n",
    "        n_layers_decoder: int = 2,\n",
    "        dropout_rate: float = 0.1,\n",
    "        region_factors: bool = True,\n",
    "        gene_likelihood: Literal[\"zinb\", \"nb\", \"poisson\"] = \"zinb\",\n",
    "        use_batch_norm: Literal[\"encoder\", \"decoder\", \"none\", \"both\"] = \"none\",\n",
    "        use_layer_norm: Literal[\"encoder\", \"decoder\", \"none\", \"both\"] = \"both\",\n",
    "        latent_distribution: Literal[\"normal\", \"ln\"] = \"normal\",\n",
    "        deeply_inject_covariates: bool = False,\n",
    "        encode_covariates: bool = False,\n",
    "        fully_paired: bool = False,\n",
    "        **model_kwargs,\n",
    "    ):\n",
    "        super().__init__(adata,\n",
    "        n_genes,\n",
    "        n_regions,\n",
    "        n_hidden,\n",
    "        n_latent,\n",
    "        n_layers_encoder,\n",
    "        n_layers_decoder,\n",
    "        dropout_rate,\n",
    "        region_factors,\n",
    "        gene_likelihood,\n",
    "        use_batch_norm,\n",
    "        use_layer_norm,\n",
    "        latent_distribution,\n",
    "        deeply_inject_covariates,\n",
    "        encode_covariates,\n",
    "        fully_paired,\n",
    "        **model_kwargs,)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_latent_representation(\n",
    "        self,\n",
    "        adata: Optional[AnnData] = None,\n",
    "        modality: Literal[\"joint\", \"expression\", \"accessibility\"] = \"joint\",\n",
    "        indices: Optional[Sequence[int]] = None,\n",
    "        give_mean: bool = True,\n",
    "        batch_size: Optional[int] = None,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Return the latent representation for each cell.\n",
    "        Parameters\n",
    "        ----------\n",
    "        adata\n",
    "            AnnData object with equivalent structure to initial AnnData. If `None`, defaults to the\n",
    "            AnnData object used to initialize the model.\n",
    "        modality\n",
    "            Return modality specific or joint latent representation.\n",
    "        indices\n",
    "            Indices of cells in adata to use. If `None`, all cells are used.\n",
    "        give_mean\n",
    "            Give mean of distribution or sample from it.\n",
    "        batch_size\n",
    "            Minibatch size for data loading into model. Defaults to `scvi.settings.batch_size`.\n",
    "        Returns\n",
    "        -------\n",
    "        latent_representation : np.ndarray\n",
    "            Low-dimensional representation for each cell\n",
    "        \"\"\"\n",
    "        if not self.is_trained_:\n",
    "            raise RuntimeError(\"Please train the model first.\")\n",
    "\n",
    "        keys = {\"z\": \"z\", \"qz_m\": \"qz_m\", \"qz_v\": \"qz_v\", \"z_expr\": \"z_expr\", \n",
    "        \"qzm_expr\": \"qzm_expr\", \"qzv_expr\": \"qzv_expr\", \"z_acc\": \"z_acc\", \"qzm_acc\": \"qzm_acc\", \"qzv_acc\": \"qzv_acc\"}\n",
    "        \n",
    "\n",
    "        adata = self._validate_anndata(adata)\n",
    "        scdl = self._make_data_loader(\n",
    "            adata=adata, indices=indices, batch_size=batch_size\n",
    "        )\n",
    "        latent = []\n",
    "        latent_expr = []\n",
    "        latent_atac = []\n",
    "        for tensors in scdl:\n",
    "            inference_inputs = self.module._get_inference_input(tensors)\n",
    "            outputs = self.module.inference(**inference_inputs)\n",
    "            qz_m = outputs[keys[\"qz_m\"]]\n",
    "            qz_v = outputs[keys[\"qz_v\"]]\n",
    "            z = outputs[keys[\"z\"]]\n",
    "            \n",
    "            qzm_expr = outputs[keys[\"qzm_expr\"]]\n",
    "            qzv_expr = outputs[keys[\"qzv_expr\"]]\n",
    "            z_expr = outputs[keys[\"z_expr\"]]\n",
    "\n",
    "            qzm_acc = outputs[keys[\"qzm_acc\"]]\n",
    "            qzm_acc = outputs[keys[\"qzv_acc\"]]\n",
    "            z_acc = outputs[keys[\"z_acc\"]]\n",
    "\n",
    "\n",
    "            if give_mean:\n",
    "                # does each model need to have this latent distribution param?\n",
    "                if self.module.latent_distribution == \"ln\":\n",
    "                    samples = Normal(qz_m, qz_v.sqrt()).sample([1])\n",
    "                    z = torch.nn.functional.softmax(samples, dim=-1)\n",
    "                    z = z.mean(dim=0)\n",
    "\n",
    "                    samples_expr = Normal(qzm_expr, qzv_expr.sqrt()).sample([1])\n",
    "                    z_expr = torch.nn.functional.softmax(samples_expr, dim=-1)\n",
    "                    z_expr = z_expr.mean(dim=0)\n",
    "\n",
    "                    samples_atac = Normal(qzm_acc, qzm_acc.sqrt()).sample([1])\n",
    "                    z_acc = torch.nn.functional.softmax(samples_atac, dim=-1)\n",
    "                    z_acc = z_acc.mean(dim=0)\n",
    "\n",
    "                else:\n",
    "                    z = qz_m\n",
    "                    z_acc = qzm_acc\n",
    "                    z_expr = qzm_expr\n",
    "\n",
    "            \n",
    "            latent += [z.cpu()]\n",
    "            latent_atac+= [z_acc.cpu()]\n",
    "            latent_expr += [z_expr.cpu()]\n",
    "\n",
    "        return torch.cat(latent).numpy() , torch.cat(latent_atac).numpy(), torch.cat(latent_expr).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('halo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8353fad07efb87fed686271f8c766cb24580e47ae7007e28a3b0368661d8351"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

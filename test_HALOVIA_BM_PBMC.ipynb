{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Iterable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Normal, Poisson\n",
    "from torch.distributions import kl_divergence as kld\n",
    "from torch import tensor\n",
    "from complementary_models import HALOVIR as HALOVI\n",
    "from complementary_models import HALOVAER as HALOVAE\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import pandas as pd\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test whole data with RNA only \n",
    "adata_multi = sc.read_h5ad(\"PBMC/CD8_Tlymph.h5ad\")\n",
    "adata_multi.obs[\"batch_id\"] = 1\n",
    "adata_multi.var[\"modality\"] =adata_multi.var[\"feature_types\"]\n",
    "adata_mvi = scvi.data.organize_multiome_anndatas(adata_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HALOVI.setup_anndata(adata_mvi, batch_key=\"modality\", time_key='latent_time')\n",
    "model = HALOVI(\n",
    "    adata_mvi,\n",
    "    n_genes=(adata_mvi.var['modality']=='Gene Expression').sum(),\n",
    "    n_regions=(adata_mvi.var['modality']=='Peaks').sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=10 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 10/10 [00:14<00:00,  1.48s/it, loss=5.9e+03, v_num=1] \n"
     ]
    }
   ],
   "source": [
    "model.train(max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=200 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [02:45<00:00,  1.21it/s, loss=1.4e+04, v_num=1] \n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=False, acc_train=True)\n",
    "model.train(max_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=200 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [02:50<00:00,  1.17it/s, loss=5.21e+03, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=True, acc_train=False)\n",
    "model.train(max_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=200 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [05:08<00:00,  1.54s/it, loss=2.78e+04, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=True, acc_train=True)\n",
    "model.train(max_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=100 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 100/100 [02:05<00:00,  1.26s/it, loss=9.78e+04, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=True, acc_train=True)\n",
    "model.module.set_finetune_params(2)\n",
    "model.train(max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=100 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 100/100 [02:05<00:00,  1.26s/it, loss=5.55e+04, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=True, acc_train=False)\n",
    "model.module.set_finetune_params(1)\n",
    "model.train(max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=100 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 100/100 [02:26<00:00,  1.46s/it, loss=8.6e+04, v_num=1] \n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=True, acc_train=True)\n",
    "model.module.set_finetune_params(2)\n",
    "model.train(max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=100 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 100/100 [02:04<00:00,  1.24s/it, loss=4.48e+04, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model.module.set_train_params(expr_train=True, acc_train=False)\n",
    "model.module.set_finetune_params(1)\n",
    "model.train(max_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cat(latent_expr).numpy(), torch.cat(latent_atac).numpy(), \\\n",
    "            torch.cat(latent_expr_dep).numpy(), torch.cat(latent_atac_dep).numpy(), \\\n",
    "                torch.cat(latent_expr_indep).numpy(), torch.cat(latent_atac_indep).numpy(), torch.cat(times).numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_expr, latent_acc,latent_expr_dep, latent_atac_dep, latent_expr_indep, latent_atac_indep, times  = model.get_latent_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## benchmark clustering \n",
    "from sklearn.metrics.cluster import adjusted_rand_score as ARI\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "\n",
    "\n",
    "latent_rep = np.concatenate((latent_expr, latent_acc), axis=1)\n",
    "adata_mvi.obsm[\"latent_rep\"] = latent_rep\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "\n",
    "latent_rep_dep = np.concatenate((latent_expr_dep, latent_atac_dep), axis=1)\n",
    "latent_rep_dep.shape\n",
    "adata_mvi.obsm[\"latent_rep_dep\"] = latent_rep_dep\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep_dep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent_dep\", resolution=0.4)\n",
    "\n",
    "latent_rep_indep = np.concatenate((latent_expr_indep, latent_atac_indep), axis=1)\n",
    "adata_mvi.obsm[\"latent_rep_indep\"] = latent_rep_indep\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep_indep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent_indep\", resolution=0.4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ari_whole 0.21310027126634526, nmi_whole: 0.32710693910568406\n",
      "ari_dep 0.18816797844561942, nmi_dep: 0.2593583939655677\n",
      "ari_indep 0.15716708953291902, nmi_indep: 0.22508399691354886\n"
     ]
    }
   ],
   "source": [
    "ari_whole = ARI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "\n",
    "\n",
    "nmi_dep = NMI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent_dep'])\n",
    "ari_dep = ARI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent_dep'])\n",
    "\n",
    "\n",
    "nmi_indep = NMI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent_indep'])\n",
    "ari_indep = ARI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent_indep'])\n",
    "\n",
    "print(\"ari_whole {}, nmi_whole: {}\".format(ari_whole, nmi_whole))\n",
    "print(\"ari_dep {}, nmi_dep: {}\".format(ari_dep, nmi_dep))\n",
    "print(\"ari_indep {}, nmi_indep: {}\".format(ari_indep, nmi_indep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score3 0.04265802739506264 and score4 0.051204012411572956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.0085, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from complementary_models import torch_infer_nonsta_dir\n",
    "\n",
    "\n",
    "latent_atac_indep = torch.tensor(latent_atac_indep).to('cuda')\n",
    "latent_expr_indep = torch.tensor(latent_expr_indep).to('cuda')\n",
    "times = torch.tensor(times).to('cuda')\n",
    "\n",
    "score3, _, _ = torch_infer_nonsta_dir(latent_atac_indep, latent_expr_indep, times)\n",
    "score4, _, _ = torch_infer_nonsta_dir(latent_expr_indep, latent_atac_indep, times)\n",
    "print(\"score3 {} and score4 {}\".format(score3, score4))\n",
    "score3 - score4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11910/565166213.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  times = torch.tensor(times).to('cuda')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1 0.056266649235981396 and score2 0.05626094452238623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.7047e-06, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_atac_dep = torch.tensor(latent_atac_dep).to('cuda')\n",
    "latent_expr_dep = torch.tensor(latent_expr_dep).to('cuda')\n",
    "times = torch.tensor(times).to('cuda')\n",
    "\n",
    "score1, _, _ = torch_infer_nonsta_dir(latent_atac_dep, latent_expr_dep, times)\n",
    "score2, _, _ = torch_infer_nonsta_dir(latent_expr_dep, latent_atac_dep, times)\n",
    "print(\"score1 {} and score2 {}\".format(score1, score2))\n",
    "score1 - score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MultiVI and GLUE test\n",
    "\n",
    "HALOVI.setup_anndata(adata_mvi, batch_key=\"modality\", time_key='latent_time')\n",
    "model2 = HALOVI(\n",
    "    adata_mvi,\n",
    "    n_genes=(adata_mvi.var['modality']=='Gene Expression').sum(),\n",
    "    n_regions=(adata_mvi.var['modality']=='Peaks').sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=100 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 100/100 [02:25<00:00,  1.46s/it, loss=5.48e+03, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model2.train(max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_expr, latent_acc,latent_expr_dep, latent_atac_dep, latent_expr_indep, latent_atac_indep, times  = model2.get_latent_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_multi_VI = 1/2 * (latent_expr+ latent_acc)\n",
    "z_multi_VI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1 0.05626836621398739 and score2 0.05625706189779424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.1304e-05, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from complementary_models import torch_infer_nonsta_dir\n",
    "\n",
    "length=z_multi_VI.shape[1]\n",
    "scores = []\n",
    "z_multi_acc = z_multi_VI[: ,:5]\n",
    "z_multi_expr = z_multi_VI[: ,5:]\n",
    "\n",
    "z_multi_acc = torch.tensor(z_multi_acc).to('cuda')\n",
    "z_multi_expr = torch.tensor(z_multi_expr).to('cuda')\n",
    "times = torch.tensor(times).to('cuda')\n",
    "score1, _, _ = torch_infer_nonsta_dir(z_multi_acc, z_multi_expr, times)\n",
    "score2, _, _ = torch_infer_nonsta_dir(z_multi_expr, z_multi_acc, times)\n",
    "\n",
    "# for i in range(0, length, 2):\n",
    "#     z1 =  torch.tensor(z_multi_VI[:, i]).to('cuda')\n",
    "#     z2 = torch.tensor(z_multi_VI[:, i+1]).to('cuda')\n",
    "#     print(z1.shape, z2.shape)\n",
    "#     score, _, _ = torch_infer_nonsta_dir(z1, z2, times)\n",
    "#     scores.append(score)\n",
    "\n",
    "print(\"score1 {} and score2 {}\".format(score1, score2))\n",
    "score1 - score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/haiyi/Desktop/HierachicalCausal_Omics/test_HALOVIA_BM_PBMC.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/haiyi/Desktop/HierachicalCausal_Omics/test_HALOVIA_BM_PBMC.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m glue_acc \u001b[39m=\u001b[39m  torch\u001b[39m.\u001b[39mtensor(latent_acc)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/haiyi/Desktop/HierachicalCausal_Omics/test_HALOVIA_BM_PBMC.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m glue_exp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(latent_expr)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/haiyi/Desktop/HierachicalCausal_Omics/test_HALOVIA_BM_PBMC.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m times \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(times)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "glue_acc =  torch.tensor(latent_acc).to('cuda')\n",
    "glue_exp = torch.tensor(latent_expr).to('cuda')\n",
    "times = torch.tensor(times).to('cuda')\n",
    "\n",
    "score1, _, _ = torch_infer_nonsta_dir(glue_acc, glue_exp, times)\n",
    "score2, _, _ = torch_infer_nonsta_dir(glue_acc, glue_exp, times)\n",
    "\n",
    "print(\"score1 {} and score2 {}\".format(score1, score2))\n",
    "score1 - score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36601\n",
      "108377\n"
     ]
    }
   ],
   "source": [
    "print((adata_mvi.var[\"feature_types\"]==\"Gene Expression\").sum())\n",
    "print((adata_mvi.var[\"feature_types\"]!=\"Gene Expression\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1934, 36601) (1934, 36601)\n"
     ]
    }
   ],
   "source": [
    "gene_expr = adata_mvi.X[:, :36601]\n",
    "gene_peak = adata_mvi.X[:, 108377:]\n",
    "print(gene_expr.shape, gene_peak.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 0/100 [14:38<?, ?it/s]\n",
      "Epoch 1/100:   0%|          | 0/100 [11:06<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "Gene_PCA = sc.pp.pca(gene_expr, n_comps=10)\n",
    "Peak_SVD = sc.pp.pca(gene_expr, n_comps=10, svd_solver='arpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11910/2506762614.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  times = torch.tensor(times).to('cuda')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1 0.056260825610453986 and score2 0.05626105133835672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-2.2573e-07, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Peak_SVD =  torch.tensor(Peak_SVD).to('cuda')\n",
    "Gene_PCA = torch.tensor(Gene_PCA).to('cuda')\n",
    "times = torch.tensor(times).to('cuda')\n",
    "\n",
    "score1, _, _ = torch_infer_nonsta_dir(Peak_SVD, Gene_PCA, times)\n",
    "score2, _, _ = torch_infer_nonsta_dir(Gene_PCA, Peak_SVD, times)\n",
    "\n",
    "print(\"score1 {} and score2 {}\".format(score1, score2))\n",
    "score1 - score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0.3562473312994934, NMI 0.4953843181608691\n"
     ]
    }
   ],
   "source": [
    "#### test the clustering \n",
    "## test the GLUE\n",
    "\n",
    "\n",
    "from sklearn.metrics.cluster import adjusted_rand_score as ARI\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "\n",
    "\n",
    "latent_rep = np.concatenate((latent_expr, latent_acc), axis=1)\n",
    "adata_mvi.obsm[\"latent_rep\"] = latent_rep\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0.24111202586923244, NMI 0.28652621046312665\n"
     ]
    }
   ],
   "source": [
    "z_multi_VI = 1/2 * (latent_expr+ latent_acc)\n",
    "adata_mvi.obsm[\"latent_rep\"] = z_multi_VI\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0.1347572955189734, NMI 0.24654630257300728\n"
     ]
    }
   ],
   "source": [
    "gene_expr = adata_mvi.X[:, :14583]\n",
    "gene_peak = adata_mvi.X[:, 14583:]\n",
    "Gene_PCA = sc.pp.pca(gene_expr, n_comps=10)\n",
    "\n",
    "adata_mvi.obsm[\"latent_rep\"] = Gene_PCA\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0.17463192634071842, NMI 0.26909877018391515\n"
     ]
    }
   ],
   "source": [
    "Peak_SVD = sc.pp.pca(gene_peak, n_comps=10, svd_solver='arpack')\n",
    "adata_mvi.obsm[\"latent_rep\"] = Peak_SVD\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('halo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8353fad07efb87fed686271f8c766cb24580e47ae7007e28a3b0368661d8351"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

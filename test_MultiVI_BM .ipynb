{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Iterable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Normal, Poisson\n",
    "from torch.distributions import kl_divergence as kld\n",
    "from torch import tensor\n",
    "from complementary_models import HALOVIR as HALOVI\n",
    "from complementary_models import HALOVAER as HALOVAE\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import pandas as pd\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test whole data with RNA only \n",
    "adata_multi = sc.read_h5ad(\"halo/E18_mouse_Brain/multiomic.h5ad\")\n",
    "adata_multi.obs[\"batch_id\"] = 1\n",
    "adata_multi.var[\"modality\"] =adata_multi.var[\"feature_types\"]\n",
    "adata_mvi = scvi.data.organize_multiome_anndatas(adata_multi)\n",
    "\n",
    "df_meta= pd.read_csv(\"halo/E18_mouse_Brain/RNA/metadata.tsv\",sep = \"\\t\",index_col=0)\n",
    "bins = df_meta.binned.unique()\n",
    "times = {}\n",
    "index = 0\n",
    "for bin in sorted(bins):\n",
    "    times[bin] = index\n",
    "    index += 1\n",
    "\n",
    "def add_time(row, times):\n",
    "    timestamp = times[row.binned]\n",
    "    return timestamp\n",
    "\n",
    "df_meta['time_key'] = df_meta.apply(lambda row: add_time(row, times), axis=1)\n",
    "\n",
    "newindex = []\n",
    "\n",
    "for idx, row in df_meta.iterrows():\n",
    "    newindex.append(idx+\"_paired\")\n",
    "\n",
    "df_meta['Id'] = newindex    \n",
    "\n",
    "df_meta_sub = df_meta[[\"Id\", 'latent_time']]\n",
    "\n",
    "df_meta_sub.set_index(\"Id\", inplace=True)\n",
    "adata_mvi.obs = adata_mvi.obs.join(df_meta_sub, how=\"inner\")\n",
    "sc.pp.filter_genes(adata_mvi, min_cells=int(adata_mvi.shape[0] * 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HALOVI.setup_anndata(adata_mvi, batch_key=\"modality\", time_key='latent_time')\n",
    "model = HALOVI(\n",
    "    adata_mvi,\n",
    "    n_genes=(adata_mvi.var['modality']=='Gene Expression').sum(),\n",
    "    n_regions=(adata_mvi.var['modality']=='Peaks').sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiyi/anaconda3/envs/halo/lib/python3.9/site-packages/scvi/model/base/_training_mixin.py:67: UserWarning: max_epochs=20 is less than n_epochs_kl_warmup=400. The max_kl_weight will not be reached during training.\n",
      "  warnings.warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 20/20 [00:52<00:00,  2.61s/it, loss=1.09e+05, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Train Multi-Vi and GLUE\n",
    "model.module.set_train_params(expr_train=True, acc_train=True)\n",
    "model.train(max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_expr, latent_acc,latent_expr_dep, latent_atac_dep, latent_expr_indep, latent_atac_indep, times  = model.get_latent_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_multi_VI = 1/2 * (latent_expr+ latent_acc)\n",
    "z_multi_VI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6350/1304969321.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z_multi_acc = torch.tensor(z_multi_acc).to('cuda')\n",
      "/tmp/ipykernel_6350/1304969321.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z_multi_expr = torch.tensor(z_multi_expr).to('cuda')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1 0.0646438486580749 and score2 0.0646493024093862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-5.4538e-06, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from complementary_models import torch_infer_nonsta_dir\n",
    "\n",
    "length=z_multi_VI.shape[1]\n",
    "scores = []\n",
    "z_multi_acc = z_multi_VI[: ,:5]\n",
    "z_multi_expr = z_multi_VI[: ,5:]\n",
    "\n",
    "z_multi_acc = torch.tensor(z_multi_acc).to('cuda')\n",
    "z_multi_expr = torch.tensor(z_multi_expr).to('cuda')\n",
    "# times = torch.tensor(times).to('cuda')\n",
    "score1, _, _ = torch_infer_nonsta_dir(z_multi_acc, z_multi_expr, times)\n",
    "score2, _, _ = torch_infer_nonsta_dir(z_multi_expr, z_multi_acc, times)\n",
    "\n",
    "# for i in range(0, length, 2):\n",
    "#     z1 =  torch.tensor(z_multi_VI[:, i]).to('cuda')\n",
    "#     z2 = torch.tensor(z_multi_VI[:, i+1]).to('cuda')\n",
    "#     print(z1.shape, z2.shape)\n",
    "#     score, _, _ = torch_infer_nonsta_dir(z1, z2, times)\n",
    "#     scores.append(score)\n",
    "\n",
    "print(\"score1 {} and score2 {}\".format(score1, score2))\n",
    "score1 - score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1 0.06458684055899336 and score2 0.06458684055899336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from complementary_models import torch_infer_nonsta_dir\n",
    "glue_acc =  torch.tensor(latent_acc).to('cuda')\n",
    "glue_exp = torch.tensor(latent_expr).to('cuda')\n",
    "times = torch.tensor(times).to('cuda')\n",
    "\n",
    "score1, _, _ = torch_infer_nonsta_dir(glue_acc, glue_exp, times)\n",
    "score2, _, _ = torch_infer_nonsta_dir(glue_acc, glue_exp, times)\n",
    "\n",
    "print(\"score1 {} and score2 {}\".format(score1, score2))\n",
    "score1 - score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3365, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glue_acc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14583\n",
      "123883\n"
     ]
    }
   ],
   "source": [
    "#### testPCA and SVD\n",
    "print((adata_mvi.var[\"feature_types\"]==\"Gene Expression\").sum())\n",
    "print((adata_mvi.var[\"feature_types\"]!=\"Gene Expression\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gene expression 14583\n",
    "## atac peak 123883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365, 138466)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_mvi.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3365, 14583) (3365, 123883)\n"
     ]
    }
   ],
   "source": [
    "gene_expr = adata_mvi.X[:, :14583]\n",
    "gene_peak = adata_mvi.X[:, 14583:]\n",
    "print(gene_expr.shape, gene_peak.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = adata_mvi.obs[\"latent_time\"]\n",
    "times = times.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(times)\n",
    "times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gene_PCA = sc.pp.pca(gene_expr, n_comps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Peak_SVD = sc.pp.pca(gene_expr, n_comps=10, svd_solver='arpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gene_PCA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6350/2506762614.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Peak_SVD =  torch.tensor(Peak_SVD).to('cuda')\n",
      "/tmp/ipykernel_6350/2506762614.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Gene_PCA = torch.tensor(Gene_PCA).to('cuda')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1 0.06462240792863325 and score2 0.06462297989043214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-5.7196e-07, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Peak_SVD =  torch.tensor(Peak_SVD).to('cuda')\n",
    "Gene_PCA = torch.tensor(Gene_PCA).to('cuda')\n",
    "times = torch.tensor(times).to('cuda')\n",
    "\n",
    "score1, _, _ = torch_infer_nonsta_dir(Peak_SVD, Gene_PCA, times)\n",
    "score2, _, _ = torch_infer_nonsta_dir(Gene_PCA, Peak_SVD, times)\n",
    "\n",
    "print(\"score1 {} and score2 {}\".format(score1, score2))\n",
    "score1 - score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0.44335601678455655, NMI 0.545887147803308\n"
     ]
    }
   ],
   "source": [
    "### running clustering for evaluation\n",
    "## GLUE\n",
    "from sklearn.metrics.cluster import adjusted_rand_score as ARI\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "\n",
    "\n",
    "latent_rep = np.concatenate((latent_expr, latent_acc), axis=1)\n",
    "adata_mvi.obsm[\"latent_rep\"] = latent_rep\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0.38418582773868637, NMI 0.4977051826934314\n"
     ]
    }
   ],
   "source": [
    "### running clustering \n",
    "### MULTIVI\n",
    "z_multi_VI = 1/2 * (latent_expr+ latent_acc)\n",
    "adata_mvi.obsm[\"latent_rep\"] = z_multi_VI\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0.3072549237229667, NMI 0.40330159694540185\n"
     ]
    }
   ],
   "source": [
    "gene_expr = adata_mvi.X[:, :14583]\n",
    "gene_peak = adata_mvi.X[:, 14583:]\n",
    "Gene_PCA = sc.pp.pca(gene_expr, n_comps=10)\n",
    "\n",
    "adata_mvi.obsm[\"latent_rep\"] = Gene_PCA\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI 0.1419958829095547, NMI 0.25848174788167677\n"
     ]
    }
   ],
   "source": [
    "Peak_SVD = sc.pp.pca(gene_peak, n_comps=10, svd_solver='arpack')\n",
    "adata_mvi.obsm[\"latent_rep\"] = Peak_SVD\n",
    "sc.pp.neighbors(adata_mvi, use_rep=\"latent_rep\")\n",
    "sc.tl.leiden(adata_mvi, key_added=\"leiden_latent\", resolution=0.4)\n",
    "ari_score = ARI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "nmi_whole = NMI(adata_mvi.obs['celltype'], adata_mvi.obs['leiden_latent'])\n",
    "print(\"ARI {}, NMI {}\".format(ari_score, nmi_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('halo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8353fad07efb87fed686271f8c766cb24580e47ae7007e28a3b0368661d8351"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
